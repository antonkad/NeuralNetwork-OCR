{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "training_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.summary.FileWriterCache.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    x =  tf.placeholder(tf.float32, [None, 784], name=\"x-input\")\n",
    "    y_ =  tf.placeholder(tf.float32, [None, 10], name=\"y-input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reseau dans couche caché les vecteurs vont des 784 inputs -> 10 outputs\n",
    "with tf.name_scope(\"weights\"):\n",
    "    W = tf.Variable(tf.zeros([784, 10]))\n",
    "#Bias (à revoir)\n",
    "with tf.name_scope(\"biases\"):\n",
    "    b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"softmax\"):\n",
    "    y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "#reduce mean: moyenne arithmetique\n",
    "#reduce sum: somme sur la deuxième dimention (0 vertical/colone - 1 horizontal/ligne)\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "#equal: revoie un boolean si les deux valeur sont egale ou pas\n",
    "#argmax: renvoie l'index de la valeur la plus haute sur la dimention definit\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    #cast: change le type d'un tensor, ici bool vers float32\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    train_op =  tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a summary for our cost and accuracy\n",
    "tf.summary.scalar(\"cost\", cross_entropy)\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  2\n",
      "Epoch:  4\n",
      "Epoch:  6\n",
      "Epoch:  8\n",
      "Accuracy:  0.9021\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.Session() as sess:\n",
    "   init = tf.global_variables_initializer()\n",
    "   sess.run(init)\n",
    "   writer = tf.summary.FileWriter('output', sess.graph)\n",
    "   \n",
    "   for epoch in range(training_epochs):\n",
    "      batch_count = int(mnist.train.num_examples/batch_size)\n",
    "      for i in range(batch_count):\n",
    "         batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "\n",
    "         _, summary = sess.run([train_op, summary_op], feed_dict={x: batch_x, y_: batch_y})\n",
    "         \n",
    "         writer.add_summary(summary, epoch * batch_count + i)\n",
    "      if epoch % 2 == 0:\n",
    "         print(\"Epoch: \", epoch)\n",
    "   print(\"Accuracy: \", accuracy.eval(feed_dict={x:mnist.test.images, y_: mnist.test.labels}))\n",
    "   writer.close()\n",
    "   print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
